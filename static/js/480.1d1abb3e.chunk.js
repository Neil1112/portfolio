"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[480],{9251:function(e,n,i){i.r(n),i.d(n,{codeString:function(){return c},markdownContent:function(){return _}});var t=i.p+"static/media/parameters-1.71f62f499b7ae2d8a581.png",o=i.p+"static/media/parameters-2.6e391c706c5a625e0699.png",s=i.p+"static/media/1.83813001fa4a43b6cd02.png",a=i.p+"static/media/2.3cafd09c455151abee29.png",r=i.p+"static/media/3.da487ce52c41d7965b59.png",m=i.p+"static/media/4.1464cd7eaee3a7c2370d.png",d=i.p+"static/media/5.205fcda20c6febce461f.png",l=i.p+"static/media/6.538b783e38ef13660080.png",_='# Recommender System: Collaborative Filtering\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1IUsqHPNIlkUqj3zpl3ClZ3tywk2w-lFT?usp=sharing)\n\nI applied the Collaborative Filtering learning algorithm to the MovieLens Dataset. The goal of a collaborative filtering recommender system is to generate two vectors. For each user a parameter vector that embodies the movie taste of a user. For each movie a feature vector of the same size which embodies some description of the movie. The dot product of the two vectors plus the bias term should produce an estimate of the rating the user might give to that movie.\n\n<iframe\n\tsrc="https://movie-recommendation-sws3b53o5yoqrbgxsjlcb4.streamlit.app/?embedded=true"\n\twidth="100%"\n\theight="550px"\n></iframe>\n\n<br/>\n\n\n![Math2Img]('.concat(a,")\n\n\n## Predict a rating for a movie for a user\n\nTo predict a rating for a movie for a user, we can use the learned featured vector for that movie and take the dot product with the user parameter vector.  By doing so, we will get the ratings for all the movies for a single user.\n\n![Math1Img](").concat(s,")\n\n\n## Collaborative Filtering learning Algorithm\n\nThe algorithm can be divided in calculating 2 cost functions. One to predict the movie ratings for a user. And other to come up with the feature vectors for the movies. Both of these cost functions are given as below with Regularisation.\n\n![Parameter1Img](").concat(t,")\n\n![Parameter2Img](").concat(o,")\n\n### Cost function for parameter vectors\n\n![Math3Img](").concat(r,")\n\n\n### Cost function for feature vectors\n\n![Math4Img](").concat(m,")\n\n\n### Total Cost function\n\nWe can combine these 2 cost functions to get the total cost function. And then use an optimisation algorithm like Gradient Descent to figure out all the parameters/features.\n\nThe Total Cost function is given by :\n\n![Math5Img](").concat(d,")\n\n\n### Recommending Movies\n\nTo recommend a movie, we can predict the rating for movie $i$ by user $j$ as :\n\n![Math6Img](").concat(l,")\n\nWe can then recommend the movies with the highest predicted ratings.\n\n\n## Implementation\n"),c='import pandas as pd\nimport numpy as np\nfrom zipfile import ZipFile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\n\n# loading the data and applying preprocessing\n# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"\n# Use the ratings.csv file\nmovielens_data_file_url = (\n    "http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"\n)\nmovielens_zipped_file = keras.utils.get_file(\n    "ml-latest-small.zip", movielens_data_file_url, extract=False\n)\nkeras_datasets_path = Path(movielens_zipped_file).parents[0]\nmovielens_dir = keras_datasets_path / "ml-latest-small"\n\n# Only extract the data the first time the script is run.\nif not movielens_dir.exists():\n    with ZipFile(movielens_zipped_file, "r") as zip:\n        # Extract files\n        print("Extracting all the files now...")\n        zip.extractall(path=keras_datasets_path)\n        print("Done!")\n\nratings_file = movielens_dir / "ratings.csv"\ndf = pd.read_csv(ratings_file)\n\n\nuser_ids = df["userId"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuserencoded2user = {i: x for i, x in enumerate(user_ids)}\nmovie_ids = df["movieId"].unique().tolist()\nmovie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\nmovie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\ndf["user"] = df["userId"].map(user2user_encoded)\ndf["movie"] = df["movieId"].map(movie2movie_encoded)\n\nnum_users = len(user2user_encoded)\nnum_movies = len(movie_encoded2movie)\ndf["rating"] = df["rating"].values.astype(np.float32)\n# min and max ratings will be used to normalize the ratings later\nmin_rating = min(df["rating"])\nmax_rating = max(df["rating"])\n\nprint(\n    "Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}".format(\n        num_users, num_movies, min_rating, max_rating\n    )\n)\n\n\n# prepare training and validation data\ndf = df.sample(frac=1, random_state=42)\nx = df[["user", "movie"]].values\n# Normalize the targets between 0 and 1. Makes it easy to train.\ny = df["rating"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n# Assuming training on 90% of the data and validating on 10%.\ntrain_indices = int(0.9 * df.shape[0])\nx_train, x_val, y_train, y_val = (\n    x[:train_indices],\n    x[train_indices:],\n    y[:train_indices],\n    y[train_indices:],\n)\n\n\n# creating the model\n# choosing an embedding size\nEMBEDDING_SIZE = 50\n\n\nclass RecommenderNet(keras.Model):\n    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n        super().__init__(**kwargs)\n        self.num_users = num_users\n        self.num_movies = num_movies\n        self.embedding_size = embedding_size\n        self.user_embedding = layers.Embedding(\n            num_users,\n            embedding_size,\n            embeddings_initializer="he_normal",\n            embeddings_regularizer=keras.regularizers.l2(1e-6),\n        )\n        self.user_bias = layers.Embedding(num_users, 1)\n        self.movie_embedding = layers.Embedding(\n            num_movies,\n            embedding_size,\n            embeddings_initializer="he_normal",\n            embeddings_regularizer=keras.regularizers.l2(1e-6),\n        )\n        self.movie_bias = layers.Embedding(num_movies, 1)\n\n    def call(self, inputs):\n        user_vector = self.user_embedding(inputs[:, 0])\n        user_bias = self.user_bias(inputs[:, 0])\n        movie_vector = self.movie_embedding(inputs[:, 1])\n        movie_bias = self.movie_bias(inputs[:, 1])\n        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n        # Add all the components (including bias)\n        x = dot_user_movie + user_bias + movie_bias\n        # The sigmoid activation forces the rating to between 0 and 1\n        return tf.nn.sigmoid(x)\n\n\nmodel = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\nmodel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(),\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n)\n\n\n# training the model\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    batch_size=64,\n    epochs=5,\n    verbose=1,\n    validation_data=(x_val, y_val),\n)\n\n# plot training and validation loss\nplt.plot(history.history["loss"])\nplt.plot(history.history["val_loss"])\nplt.title("model loss")\nplt.ylabel("loss")\nplt.xlabel("epoch")\nplt.legend(["train", "test"], loc="upper left")\nplt.show()\n\n\n# show top 10 movie recommendations to a user\nmovie_df = pd.read_csv(movielens_dir / "movies.csv")\n\n# Let us get a user and see the top recommendations.\nuser_id = df.userId.sample(1).iloc[0]\nmovies_watched_by_user = df[df.userId == user_id]\nmovies_not_watched = movie_df[\n    ~movie_df["movieId"].isin(movies_watched_by_user.movieId.values)\n]["movieId"]\nmovies_not_watched = list(\n    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n)\nmovies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\nuser_encoder = user2user_encoded.get(user_id)\nuser_movie_array = np.hstack(\n    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n)\nratings = model.predict(user_movie_array).flatten()\ntop_ratings_indices = ratings.argsort()[-10:][::-1]\nrecommended_movie_ids = [\n    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n]\n\nprint("Showing recommendations for user: {}".format(user_id))\nprint("====" * 9)\nprint("Movies with high ratings from user")\nprint("----" * 8)\ntop_movies_user = (\n    movies_watched_by_user.sort_values(by="rating", ascending=False)\n    .head(5)\n    .movieId.values\n)\nmovie_df_rows = movie_df[movie_df["movieId"].isin(top_movies_user)]\nfor row in movie_df_rows.itertuples():\n    print(row.title, ":", row.genres)\n\nprint("----" * 8)\nprint("Top 10 movie recommendations")\nprint("----" * 8)\nrecommended_movies = movie_df[movie_df["movieId"].isin(recommended_movie_ids)]\nfor row in recommended_movies.itertuples():\n    print(row.title, ":", row.genres)\n\n\n# save the model\nfrom tensorflow.keras.models import load_model, save_model\n\n# Save the model to an tf file\nmodel.save(\'collaborative_filtering_model.tf\')\n\n!zip -r ./collaborative_filtering_model.tf.zip collaborative_filtering_model.tf\n'}}]);
//# sourceMappingURL=480.1d1abb3e.chunk.js.map