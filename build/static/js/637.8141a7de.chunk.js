"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[637],{1384:function(e,n,i){i.r(n),i.d(n,{codeString:function(){return s},markdownContent:function(){return a}});var t=i.p+"static/media/discriminator_training.dfec74a6fb1d306565f9.jpg",r=i.p+"static/media/generator_training.7b5d09b32f86778f1868.jpg",a="\n# GAN Implementation in PyTorch\n\nGenerative Adversarial Networks (GANs) are widely used to generate realistic images. They use two neural networks which competes against each other. One is Generator and other is Discriminator.\n\n\n\n## Discriminator\nThe Discriminator is a neural network whose task is to classify the given image as real or fake. The goal of the discriminator is to model the probability of each class given a set of input features.\ni.e. -\n$$\n  p(y|x)\n$$\n\nwhere $y$ is the class and $x$ is the input features.\n\n![Discriminator Training](".concat(t,")\n\n\n\n\n\n## Generator\nThe Generator is a neural network whose task is to generate fake images. It takes a random noise as input and generates an image.\nThe goal of the generator is to fool the discriminator by generating fake images that are indistinguishable from real images.\nOnce the generator is trained, you freeze its parameters and use it to generate images by passing random noise as input. This is known as Sampling.\n\nThus Generator gives - \n$$\n  p(x|y)\n$$\ni.e. - probability of generating an image $x$ given a class $y$.\n\n![Generator Training](").concat(r,")\n\n\n\n\n\n## Implementation\nThe following code snippet shows how to implement a GAN in Python using PyTorch.\n"),s="# import libraries\nimport torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST # Training dataset\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\ntorch.manual_seed(0)\n\n# function to display images\ndef show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n  '''\n  Function for visualizing images: Given a tensor of images, number of images, and size per image, plots and prints the image in a uniform grid.\n  '''\n  image_unflat = image_tensor.detach().cpu().view(-1, *size)\n  image_grid = make_grid(image_unflat[:num_images], nrow=5)\n  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n  plt.show()\n\n# generator block\ndef get_generator_block(input_dim, output_dim):\n  '''\n    Function for returning a block of the generator's neural network\n    given input and output dimensions.\n    Parameters:\n        input_dim: the dimension of the input vector, a scalar\n        output_dim: the dimension of the output vector, a scalar\n    Returns:\n        a generator neural network layer, with a linear transformation\n          followed by a batch normalization and then a relu activation\n  '''\n  return nn.Sequential(\n      nn.Linear(input_dim, output_dim),\n      nn.BatchNorm1d(output_dim),\n      nn.ReLU(inplace=True)\n  )\n\n# generator class\nclass Generator(nn.Module):\n  '''\n  Generator Class\n  Values:\n      z_dim: the dimension of the noise vector, a scalar\n      im_dim: the dimension of the images, fitted for the dataset used, a scalar\n        (MNIST images are 28 x 28 = 784 so that is your default)\n      hidden_dim: the inner dimension, a scalar\n  '''\n  def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n    super(Generator, self).__init__()\n\n    # Build the neural network\n    self.gen = nn.Sequential(\n        get_generator_block(z_dim, hidden_dim),\n        get_generator_block(hidden_dim, hidden_dim * 2),\n        get_generator_block(hidden_dim * 2, hidden_dim * 4),\n        get_generator_block(hidden_dim * 4, hidden_dim * 8),\n        # the last layer is different\n        nn.Linear(hidden_dim * 8, im_dim),\n        nn.Sigmoid()\n    )\n\n  # Forward pass method\n  def forward(self, noise):\n    '''\n    Function for completing a forward pass of the generator: Given a noise tensor,\n    returns generated images.\n    Parameters:\n        noise: a noise tensor with dimensions (n_samples, z_dim)\n    '''\n    return self.gen(noise)\n\n# function to get noise\ndef get_noise(n_samples, z_dim, device='cuda'):\n  '''\n  Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n  creates a tensor of that shape filled with random numbers from the normal distribution.\n  Parameters:\n      n_samples: the number of samples to generate, a scalar\n      z_dim: the dimension of the noise vector, a scalar\n      device: the device type\n  '''\n  return torch.randn(n_samples, z_dim, device=device)\n\n\n# discriminator block\ndef get_discriminator_block(input_dim, output_dim):\n  '''\n  Discriminator Block\n  Function for returning a neural network of the discriminator given input and output dimensions.\n  Parameters:\n      input_dim: the dimension of the input vector, a scalar\n      output_dim: the dimension of the output vector, a scalar\n  Returns:\n      a discriminator neural network layer, with a linear transformation\n        followed by an nn.LeakyReLU activation with negative slope of 0.2\n        (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)\n  '''\n  return nn.Sequential(\n      nn.Linear(input_dim, output_dim),\n      nn.LeakyReLU(negative_slope=0.2)\n  )\n\n# discriminator class\nclass Discriminator(nn.Module):\n  '''\n  Discriminator Class\n  Values:\n      im_dim: the dimension of the images, fitted for the dataset used, a scalar\n          (MNIST images are 28x28 = 784 so that is your default)\n      hidden_dim: the inner dimension, a scalar\n  '''\n  def __init__(self, im_dim=784, hidden_dim=128):\n    super(Discriminator, self).__init__()\n\n    # Build the neural network\n    self.disc = nn.Sequential(\n      get_discriminator_block(im_dim, hidden_dim * 4),\n      get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n      get_discriminator_block(hidden_dim * 2, hidden_dim),\n      nn.Linear(hidden_dim, 1)\n    )\n\n\n  # Forward pass method\n  def forward(self, image):\n    '''\n    Function for completing a forward pass of the discriminator: Given an image tensor,\n    returns a 1-dimension tensor representing fake/real.\n    Parameters:\n        image: a flattened image tensor with dimension (im_dim)\n    '''\n    return self.disc(image)\n\n\n# Set your parameters\ncriterion = nn.BCEWithLogitsLoss()\nn_epochs = 200\nz_dim = 64\ndisplay_step = 500\nbatch_size = 128\nlr = 0.00001\n\n# Load MNIST dataset as tensors\ndataloader = DataLoader(\n    MNIST('.', download=True, transform=transforms.ToTensor()),\n    batch_size=batch_size,\n    shuffle=True\n)\n\ndevice = 'cuda'\n\n\n# Initialize generator and discriminator\ngen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\ndisc = Discriminator().to(device)\ndisc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n\n\n# function to calculate discriminator loss\ndef get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n  '''\n  Return the loss of the discriminator given inputs.\n  Parameters:\n      gen: the generator model, which returns an image given z-dimensional noise\n      disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n      criterion: the loss function, which should be used to compare\n              the discriminator's predictions to the ground truth reality of the images\n              (e.g. fake = 0, real = 1)\n      real: a batch of real images\n      num_images: the number of images the generator should produce,\n              which is also the length of the real images\n      z_dim: the dimension of the noise vector, a scalar\n      device: the device type\n  Returns:\n      disc_loss: a torch scalar loss value for the current batch\n  '''\n  noise_vectors = get_noise(num_images, z_dim, device=device)\n  fake_images = gen(noise_vectors)\n\n  disc_preds_for_fakes = disc(fake_images.detach())\n  true_labels_for_fakes = torch.zeros_like(disc_preds_for_fakes)\n  disc_loss_for_fakes = criterion(disc_preds_for_fakes, true_labels_for_fakes)\n\n  disc_preds_for_reals = disc(real)\n  true_labels_for_reals = torch.ones_like(disc_preds_for_reals)\n  disc_loss_for_reals = criterion(disc_preds_for_reals, true_labels_for_reals)\n\n  disc_loss = (disc_loss_for_fakes + disc_loss_for_reals) / 2\n\n  return disc_loss\n\n# function to calculate generator loss\ndef get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n  '''\n  Return the loss of the generator given inputs.\n  Parameters:\n      gen: the generator model, which returns an image given z-dimensional noise\n      disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n      criterion: the loss function, which should be used to compare\n              the discriminator's predictions to the ground truth reality of the images\n              (e.g. fake = 0, real = 1)\n      num_images: the number of images the generator should produce,\n              which is also the length of the real images\n      z_dim: the dimension of the noise vector, a scalar\n      device: the device type\n  Returns:\n      gen_loss: a torch scalar loss value for the current batch\n  '''\n  noise_vectors = get_noise(num_images, z_dim, device=device)\n  fake_images = gen(noise_vectors)\n\n  disc_preds_for_fakes = disc(fake_images)\n  gen_loss = criterion(disc_preds_for_fakes, torch.ones_like(disc_preds_for_fakes))\n\n  return gen_loss\n\n\n# Actual training\ncur_step = 0\nmean_generator_loss = 0\nmean_discriminator_loss = 0\ngen_loss = False\nerror = False\n\nfor epoch in range(n_epochs):\n\n  # Dataloader returns the batches\n  for real, _ in tqdm(dataloader):\n    cur_batch_size = len(real)\n\n    # Flatten the batch of real images from the dataset\n    real = real.view(cur_batch_size, -1).to(device)\n\n    ### Update discriminator ###\n    disc_opt.zero_grad()\n    disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n    disc_loss.backward(retain_graph=True)\n    disc_opt.step()\n\n    ### Update generator ###\n    gen_opt.zero_grad()\n    gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n    gen_loss.backward(retain_graph=True)\n    gen_opt.step()\n\n\n    # keep track of the average disc loss\n    mean_discriminator_loss += disc_loss.item() / display_step\n\n    # Keep track of the average generator loss\n    mean_generator_loss += gen_loss.item() / display_step\n\n    ### Visualization code ###\n    if cur_step % display_step == 0 and cur_step > 0:\n      print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n      fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n      fake = gen(fake_noise)\n      show_tensor_images(fake)\n      show_tensor_images(real)\n      mean_generator_loss = 0\n      mean_discriminator_loss = 0\n    cur_step += 1\n"}}]);
//# sourceMappingURL=637.8141a7de.chunk.js.map